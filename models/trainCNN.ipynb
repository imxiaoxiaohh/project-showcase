{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FX4RYHABGMRk"
   },
   "source": [
    "### Download data from kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VMLu8uslDXuZ"
   },
   "outputs": [],
   "source": [
    "# Install necessary libraries\n",
    "!pip install torch torchvision torchaudio opencv-python matplotlib numpy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fwLSW464J34x"
   },
   "outputs": [],
   "source": [
    "!mkdir dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9Qs6hcM7LOFV"
   },
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "\n",
    "files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SJXyCQevL_Aj"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hmqNzulILofS"
   },
   "outputs": [],
   "source": [
    "!kaggle datasets download -d xainano/handwrittenmathsymbols\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QaNOxdMkLxYU"
   },
   "outputs": [],
   "source": [
    "import zipfile\n",
    "\n",
    "# Unzip dataset\n",
    "dataset_path = \"/content/handwrittenmathsymbols.zip\"\n",
    "with zipfile.ZipFile(dataset_path, \"r\") as zip_ref:\n",
    "    zip_ref.extractall(\"/content/handwritten_math_symbols\")\n",
    "\n",
    "print(\"Dataset extracted successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c4C4MAdpMiCu"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# List dataset files\n",
    "dataset_dir = \"/content/handwritten_math_symbols\"\n",
    "print(os.listdir(dataset_dir))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SnTQ9Tf4MrGl"
   },
   "outputs": [],
   "source": [
    "!apt-get install unrar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "sNibvqRWOKQN"
   },
   "outputs": [],
   "source": [
    "!unrar x \"/content/handwritten_math_symbols/data.rar\" \"/content/handwritten_math_symbols_extracted/\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AqoICFwLSaVi"
   },
   "source": [
    "### Filter needed classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wCXcecJ2XDGO"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torch.utils.data as data\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "from PIL import Image\n",
    "from google.colab import drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yr-jj-8zDTrX"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Paths\n",
    "original_dataset_path = \"/content/handwritten_math_symbols_extracted/extracted_images\"\n",
    "filtered_dataset_path = \"/content/filtered_dataset\"  # New dataset path\n",
    "\n",
    "# Selected classes (numbers, characters, basic arithmetic symbols)\n",
    "selected_classes = [\n",
    "    '0', '1', '2', '3', '4', '5', '6', '7', '8', '9',\n",
    "    'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z',\n",
    "    'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z',\n",
    "    '(', ')', '+', '-', '=', 'forward_slash', 'times', ',', '.'\n",
    "]\n",
    "\n",
    "# Create new dataset directory if not exists\n",
    "os.makedirs(filtered_dataset_path, exist_ok=True)\n",
    "\n",
    "# Copy only selected class folders to the new dataset path\n",
    "for cls in selected_classes:\n",
    "    src_folder = os.path.join(original_dataset_path, cls)\n",
    "    dest_folder = os.path.join(filtered_dataset_path, cls)\n",
    "\n",
    "    if os.path.exists(src_folder):  # Only copy if class exists in original dataset\n",
    "        shutil.copytree(src_folder, dest_folder, dirs_exist_ok=True)  # Copy images\n",
    "\n",
    "\n",
    "print(f\"Filtered dataset saved at: {filtered_dataset_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6suHqaVVSfm-"
   },
   "source": [
    "### Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Zd-DqZJ0DqXn"
   },
   "outputs": [],
   "source": [
    "# Define transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=1),  # Convert to grayscale\n",
    "    transforms.Resize((28, 28)),  # Resize to 28x28\n",
    "    transforms.ToTensor(),  # Convert to tensor\n",
    "    transforms.Normalize((0.5,), (0.5,))  # Normalize pixel values [-1,1]\n",
    "])\n",
    "\n",
    "# Load the NEW dataset\n",
    "filtered_dataset = datasets.ImageFolder(root=filtered_dataset_path, transform=transform)\n",
    "\n",
    "# Create DataLoader\n",
    "train_size = int(0.8 * len(filtered_dataset))\n",
    "val_size = len(filtered_dataset) - train_size\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(filtered_dataset, [train_size, val_size])\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "# Print class labels\n",
    "classes = filtered_dataset.classes\n",
    "print(f\"Final Selected Classes: {classes}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "uGRThkRiYNjO"
   },
   "outputs": [],
   "source": [
    "def imshow(img, label):\n",
    "    img = img.numpy().squeeze()  # Convert tensor to NumPy & remove extra dims\n",
    "    plt.imshow(img, cmap='gray')\n",
    "    plt.title(f\"Label: {filtered_dataset.classes[label]}\")\n",
    "    plt.show()\n",
    "\n",
    "# Get one batch of data\n",
    "dataiter = iter(train_loader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# Show first 5 images\n",
    "for i in range(5):\n",
    "    imshow(images[i], labels[i])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p4yS07rAPJoQ"
   },
   "outputs": [],
   "source": [
    "# CNN Model\n",
    "class MathSymbolCNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(MathSymbolCNN, self).__init__()\n",
    "\n",
    "        self.conv_layers = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1),  # Conv1\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 32, kernel_size=3, stride=2, padding=1),  # Conv2 (stride=2 downsamples)\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),  # Conv3\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, stride=2, padding=1),  # Conv4 (stride=2 downsamples)\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 32, kernel_size=3, stride=1, padding=1),  # Conv5\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(32 * 7 * 7, 768),  # Fully connected layer 1\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(768, 128),  # Fully connected layer 2\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, num_classes)  # Output layer (num_classes = number of symbols)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_layers(x)\n",
    "        x = self.fc_layers(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GukcLfmFPQpn"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Initialize model\n",
    "num_classes = len(classes)  # Number of math symbols\n",
    "model = MathSymbolCNN(num_classes).to(device)\n",
    "\n",
    "# Define Loss Function & Optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "paabSHqzPn3S"
   },
   "outputs": [],
   "source": [
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct, total = 0, 0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    train_acc = 100 * correct / total\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {running_loss:.4f}, Accuracy: {train_acc:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O3VKxRNDTG40"
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "correct, total = 0, 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in val_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "val_acc = 100 * correct / total\n",
    "print(f\"Validation Accuracy: {val_acc:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H7dYWrI2PplX"
   },
   "outputs": [],
   "source": [
    "# Define the path in Google Drive\n",
    "model_path = \"/content/drive/My Drive/math_cnn_improve.pth\"\n",
    "\n",
    "# Save the trained model\n",
    "torch.save(model.state_dict(), model_path)\n",
    "print(f\"Model saved at: {model_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jmmMXHfrkLjN"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
